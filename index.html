<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Gautham Narayan Narasimhan</title>

  <meta name="author" content="Gautham Narayan Narasimhan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table
    style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Gautham Narayan Narasimhan</name>
                  </p>
                  <p style="text-align:justify">
                    Hello! I am currently a senior perception engineer at <a href="https://www.aeva.com/">Aeva</a> working on developing 
                    machine learning products for lidar data. Previously, I worked as a computer vision research engineer
                    at <a href="https://www.path-robotics.com/">Path Robotics</a> to build the perception stack for autonomous robotic welding. 
                  </p>
                  
                  <p style="text-align:justify">
                    In another life I was a research assistant at the Robotics Institute (RI) at Carnegie Mellon
                    University where I completed my masters thesis with
                    <a href="https://davheld.github.io/">Prof. David Held</a> at CMU. 
                    I'm study machine learning algorithms that enable robots to perceive and interact with the real world. 
                  </p>
                  <p style="text-align:left">
                    Contact: gauthamnarayn (at) gmail.com
                  </p>
                  <p style="text-align:center">
                    <a href="resources/Resume_November_2022.pdf">Resume</a> &nbsp/&nbsp
                    <a href="https://github.com/gauthamnarayan">GitHub</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=4m-uVKUAAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/gautham-narayan-80077296/">LinkedIn</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:25%;max-width:25%">
                  <img style="width:100%;max-width:100%" alt="profile photo" src="images/gautham_dp_cropped.jpg"
                    class="hoverZoomLink">
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:5px;width:100%;vertical-align:middle">
                      <heading>News</heading>
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:5px;width:100%;vertical-align:middle">
                      <span class="tab">
                        <b> Nov 2022 : </b> Joined Aeva as a senior perception engineer to work on ML models for Lidar data
                      </span>
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:5px;width:100%;vertical-align:middle">
                      <span class="tab">
                        <b> June 2022 : </b> Carnegie Mellon SCS wrote an article on our work in Robotic Pouring - [<a
                          href="https://www.cs.cmu.edu/news/2022/robots-pouring-water">Link</a>]
                      </span>
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:5px;width:100%;vertical-align:middle">
                      <span class="tab">
                        <b> Jan 2022 : </b> <a
                          href="https://sites.google.com/view/transparentliquidpouring">Self-supervised Transparent
                          Liquid Segmentation for Robotic Pouring</a> accepted to ICRA 2022!
                      </span>
                    </td>
                  </tr>
                  <tr>
                    <td style="padding:5px;width:100%;vertical-align:middle">
                      <span class="tab">
                        <b> Oct 2020 : </b> <a href="https://arxiv.org/pdf/2011.06777.pdf">ROLL: Visual Self-Supervised
                          Reinforcement Learning with Object Reasoning</a> accepted to CoRL 2020!
                      </span>
                    </td>
                  </tr>
                </tbody>
              </table>

              <br><br>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:0px;width:100%;vertical-align:middle">
                          <heading>Invited Talks</heading>
                        </td>
                      </tr>
                      <tr>
                        <td style="padding:5px;width:100%;vertical-align:middle">
                          <span class="tab">
                            <b> July 2022 : </b> <b> Intel Embodied AI Lab </b> - <i> Transparent Liquid Image
                              Segmentation For Robotic Pouring </i>
                            [<a
                              href="https://docs.google.com/presentation/d/1ZOSfzL6JulYXiRLVonhIEH9OToLpr5P4tDUYnsBegPQ/edit?usp=sharing">Slides</a>]
                          </span>
                        </td>
                      </tr>
                    </tbody>
                  </table>

                  <br><br>

                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:0px;width:100%;vertical-align:middle">
                          <heading>Research and Publications</heading>
                        </td>
                      </tr>
                    </tbody>
                  </table>
                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>

                      <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle" align="center">
                          <img src="images/pouring_2021.jpg" alt="clean-usnob" width="320" height="160">
                        </td>
                        <td width="75%" valign="middle">
                          <papertitle>Learning Material Properties using a Differentiable Simulator for Liquid/Granular
                            manipulation</papertitle><br>
                          <strong>Gautham Narayan</strong>, Xingyu Lin, David Held<br>
                          <em>In progress</em><br>
                          <p style="text-align:justify"> Currently training a Material Point Method based differentiable
                            simulator to learn material properties. Cross Entropy Method has shown
                            good performance for trajectory optimization once the material properties have been learnt.
                            More details coming soon ...
                          </p>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle" align="center">
                          <img src="images/Transparent_liquid_pouring_icra2022_thumbnail.jpg" alt="clean-usnob"
                            width="320" height="160">
                        </td>
                        <td width="75%" valign="middle">
                          <papertitle>Self-supervised Transparent Liquid Segmentation for Robotic Pouring</papertitle>
                          <br>
                          <strong>Gautham Narayan</strong>, Kai Zhang, Ben Eisner, Xingyu Lin, David Held<br>
                          <em><a href="https://www.icra2022.org/">ICRA 2022</a> and abridged at NeurIPS 2021 Deep
                            Generative
                            Models Workshop</a></em><br>
                          <p style="text-align:justify"> A novel segmentation pipeline that can segment transparent
                            liquids
                            such
                            as water from a static,
                            RGB image without requiring any manual annotations. We show that this system can run in
                            real-time
                            and aid in tasks such
                            as robotic pouring.
                          </p>
                          <a href="https://arxiv.org/abs/2203.01538">[Paper]</a>
                          <a href="https://sites.google.com/view/transparentliquidpouring">[Website]</a><br>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle" align="center">
                          <img src="images/2020_ROLL.jpg" alt="clean-usnob" width="320" height="160">
                        </td>
                        <td width="75%" valign="middle">
                          <papertitle>ROLL: Visual Self-Supervised Reinforcement Learning with Object Reasoning
                          </papertitle>
                          <br>
                          Yufei Wang*, <strong>Gautham Narayan*</strong>, Xingyu Lin, Brian Okorn, David Held<br>
                          <em>* denotes equal contribution</em><br>
                          <em><a href="https://sites.google.com/robot-learning.org/corl2020">Conference on Robot
                              Learning,
                              CoRL
                              2020</a></em><br>
                          <p style="text-align:justify">Unknown object segmentation to learn a visual representation
                            that
                            can
                            reason about occlusions. Our method achieves
                            state of the art on object manipulation benchmarking tasks.</p>
                          <a href="https://arxiv.org/pdf/2011.06777.pdf">[Paper]</a>
                          <a href="https://sites.google.com/andrew.cmu.edu/roll/home">[Website]</a><br>
                        </td>
                      </tr>

                      <tr>
                        <!--<td style="padding:20px;width:25%;vertical-align:middle;horizontal-align:middle">-->
                        <td style="padding:20px;width:25%;vertical-align:middle;horizontal-align:middle" align="center">
                          <img src="images/thesis_2020.png" alt="clean-usnob" width="220" height="160">
                        </td>
                        <td width="75%" valign="middle">
                          <papertitle>Segmentation for learning image based goal conditioned policies</papertitle><br>
                          <strong>Gautham Narayan</strong>, David Held<br>
                          <em>Master's Thesis - Carnegie Mellon University, 2020</em><br>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                          <img src="images/CSAFE_2020.png" alt="clean-usnob" width="320" height="160" align="center">
                        </td>
                        <td width="75%" valign="middle">
                          <papertitle>Experimental Droplet Spatter Analysis Using Least Squares Approximation
                          </papertitle>
                          <br>
                          <strong>Gautham Narayan</strong>, Bill Eddy<br>
                          <em>Internal Report - NIST Center of Excellence in Forensic Science, 2020</em><br>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                          <img src="images/AST_2016.png" alt="clean-usnob" width="320" height="200">
                        </td>
                        <td width="75%" valign="middle">
                          <papertitle>Effect of winglets induced tip vortex structure on the performance of subsonic
                            wings
                          </papertitle><br>
                          <strong>Gautham Narayan</strong>, Bibin John<br>
                          <em>Elsevier - Aerospace Science and Technology, 2016</em><br>
                          <p>
                            Design optimization for subsonic winglets using computational fluid dynamics.
                          </p>
                          <a href="https://www.sciencedirect.com/science/article/abs/pii/S1270963816305569">[Paper]</a>
                        </td>
                      </tr>

                      <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                          <tr>
                            <td style="padding:0px">
                              <br>
                              <p style="text-align:right;font-size:small;">
                                <a href="https://github.com/jonbarron/website">Source</a>
                              </p>
                            </td>
                          </tr>
                        </tbody>
                      </table>
        </td>
      </tr>
  </table>
</body>

</html>
